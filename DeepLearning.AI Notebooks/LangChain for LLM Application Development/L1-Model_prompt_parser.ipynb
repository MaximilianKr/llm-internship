{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69cbffe4-ca09-4437-a505-d1c13c3e9ed8",
   "metadata": {},
   "source": [
    "# LangChain: Models, Prompts and Output Parsers\n",
    "\n",
    "\n",
    "## Outline\n",
    "\n",
    " * Direct API calls to OpenAI\n",
    " * API calls through LangChain:\n",
    "   * Prompts\n",
    "   * Models\n",
    "   * Output parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f577c1-48e2-4223-b0b2-cf22279f9ac4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## EITHER: get your [OpenAI API Key](https://platform.openai.com/account/api-keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4be4c94-2e09-4b9e-b8e5-c2bedf3606d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv\n",
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15071c55-b883-421d-a5fa-56c9f78ffbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "# openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41be4694-5e63-459f-ae37-59147452fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_name = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_name = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc09c10-1587-4df1-aa4e-5a3abc72a372",
   "metadata": {},
   "source": [
    "## OR: use [LocalAI as an OpenAI replacement](https://localai.io/howtos/easy-request-openai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cdcb2a9-034a-4bc3-aa89-6e7975a0c98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# Specify the port your LocalAI docker container runs on\n",
    "openai.api_base = \"http://localhost:8080/v1\"\n",
    "openai.api_key = \"sx-xxx\"  # not needed for LocalAI (dummy)\n",
    "OPENAI_API_KEY = \"sx-xxx\"\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "830821e3-ee35-47ca-8993-ac4de5beedb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model you are using\n",
    "# llm_name = \"\"\n",
    "llm_name = \"lunademo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4c1345-9ad1-4c8e-93bb-fceecd069db3",
   "metadata": {},
   "source": [
    "## Chat API : OpenAI\n",
    "\n",
    "Let's start with a direct API calls to OpenAI.</br>\n",
    "In this example we write a custom function to do what we can later more easily achieve with LangChain (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3082d8db-af53-4dbb-a390-bd9edf2b9c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=llm_model):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "525b0675-a33b-4f39-bf5d-37972809feda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You would have 3 bananas left.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(\"I have 5 bananas and I eat 3. I also get another 1 as a present. How many do I have left?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d17c609d-f475-4c0b-9c1b-6541e00a6da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Aaaah!!!! I need an OpenAI API key to run this. \\\n",
    "I got one with $18 Credits back in March '23, \\\n",
    "but the credits expired without me using them! \\\n",
    "And now OpenAI won't let me create a new account, \\\n",
    "because my phone number has already been used! \\\n",
    "And I don't have a credit card, \\\n",
    "to pay for a subscription!!! \\\n",
    "So we need to find an Open Source model!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faf77984-6f53-4183-9e77-b83505f1e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = \"\"\"Pirate English \\\n",
    "in a relaxed tone\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c07720ec-9402-474d-9369-582fe3e12ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks \n",
      "into a style that is Pirate English in a relaxed tone.\n",
      "text: ```\n",
      "Aaaah!!!! I need an OpenAI API key to run this. I got one with $18 Credits back in March '23, but the credits expired without me using them! And now OpenAI won't let me create a new account, because my phone number has already been used! And I don't have a credit card, to pay for a subscription!!! So we need to find an Open Source model!!!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \n",
    "into a style that is {style}.\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f755edbe-216e-42b6-b69d-9a49ed59e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c2f52ba-8fe9-40cd-bed9-0b0fd616c26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Arrrr!!!! Me hearties, me be needin' an OpenAI API key to run this here program. I did manage to get one wit' $18 Credits back in March '23, but the credits expired without me usin' 'em! And now OpenAI won't let me create a new account, because me phone number has already been used! And I don't have a credit card, to pay for a subscription!!! So we need to find an Open Source model!!!\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f503f831-39d3-4865-9de1-bc6c1b1adea0",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb4d697-9cef-4757-8124-882999ad84df",
   "metadata": {},
   "source": [
    "> Uff!!! I bruche en OpenAI API-Schlüssel, um das z'laufe. Ich ha im März '23 en mit $18 Guthabe übercho, aber s Guthabe isch verfalle ohni dass ich's brucht ha! Und jetzt laht mich OpenAI kei neus Konto erstelle, will mini Telefonnummer scho benutzt worde isch! Und ich ha kei Kreditkart, um für es Abonnement z'zahle!!! Mir müend also en Open Source Modell finde!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadd00d9-f587-4826-8903-f0c61bad7638",
   "metadata": {},
   "source": [
    "## Chat API : LangChain\n",
    "\n",
    "Let's try how we can do the same using LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18319cce-fd9d-48f6-8414-50dca0b8673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d306f01-c26a-47ed-b4bb-02e2483d7538",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "155b0058-edc3-49f2-9729-921039a9a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4f3174-a9de-4ca6-ab45-8222ae8404c6",
   "metadata": {},
   "source": [
    "### Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72f0e098-3ad7-4d7c-855a-100bc92af79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df60b1f4-983f-4e3d-bd61-1af21d975d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ebfa5ae-ea4f-4fab-944b-b90d96b55e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['style', 'text'], template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfa214d3-b15d-4d73-8f64-ce4cf6ada467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['style', 'text']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "714d03a2-953c-4831-aec9-df38c2e48f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_style = \"\"\"Caribbean Pirate English \\\n",
    "in a relaxed tone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b75e4abe-ea5e-4737-ac3b-0ffd8850d34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Aaaah!!!! I need an OpenAI API key to run this. \\\n",
    "I got one with $18 Credits back in March '23, \\\n",
    "but the credits expired without me using them! \\\n",
    "And now OpenAI won't let me create a new account, \\\n",
    "because my phone number has already been used! \\\n",
    "And I don't have a credit card, \\\n",
    "to pay for a subscription!!! \\\n",
    "So we need to find an Open Source model!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2146dbc-0d27-4ed7-b307-770b7523f366",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=customer_style,\n",
    "                    text=customer_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a92ed06d-2d54-4c0d-b417-ae938e9c4bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain.schema.messages.HumanMessage'>\n"
     ]
    }
   ],
   "source": [
    "print(type(customer_messages))\n",
    "print(type(customer_messages[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bdb95cdc-93c6-4dfe-9b2f-f77c43f3be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "customer_response = chat(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a899a203-88cc-4cdb-98f4-b64cb31605a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrr!!!! Ye scallywags! Me be needin' an OpenAI API key t' run this here program. Back in March '23, I found me one that came with $18 Credits, but the looting scoundrels expired without me gettin' to use 'em! Now OpenAI won't be lettin' me create a new account, claimin' that me phone number's already been used. And to make matters worse, I don't be havin' a credit card to pay for a subscription! So, me hearties, we be needin' t' find an Open Source model - savvy?\n"
     ]
    }
   ],
   "source": [
    "print(customer_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7987f03b-637d-424b-8cf5-cacde7a678b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_reply = \"\"\"Hey there customer, \\\n",
    "the warranty does not cover \\\n",
    "cleaning expenses for your kitchen \\\n",
    "because it's your fault that \\\n",
    "you misused your blender \\\n",
    "by forgetting to put the lid on before \\\n",
    "starting the blender. \\\n",
    "Tough luck! See ya!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d19ed98a-d22b-436e-80d3-a7e404d4964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_style_pirate = \"\"\"\\\n",
    "a impolite tone \\\n",
    "that speaks in Pirate\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9325a98f-ee29-4e12-9271-13fb65b113dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks into a style that is a impolite tone that speaks in Pirate. text: ```Hey there customer, the warranty does not cover cleaning expenses for your kitchen because it's your fault that you misused your blender by forgetting to put the lid on before starting the blender. Tough luck! See ya!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "service_messages = prompt_template.format_messages(\n",
    "    style=service_style_pirate,\n",
    "    text=service_reply)\n",
    "\n",
    "print(service_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b462835-9652-4372-b6b5-d46d7135d356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrgghh matey! Listen here ye scurvy customer, the blasted warranty be not coverin' yer grog-infused cleaning expenses for yer kitchen. It be yer own fault that ye misused the infernal blender by forgettin' to put the cursed lid on before startin' it up. So tough luck and walk the plank! Farewell, ye landlubber!\n"
     ]
    }
   ],
   "source": [
    "service_response = chat(service_messages)\n",
    "print(service_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedb3c4e-cc5b-4356-9cff-b6ad929d4116",
   "metadata": {},
   "source": [
    "## Output Parsers\n",
    "\n",
    "Let's start with defining how we would like the LLM output to look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc4c2d6f-937c-4115-a1de-3bff5f57b76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False, 'delivery_days': 5, 'price_value': 'pretty affordable!'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"pretty affordable!\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7721f9cd-f6c0-4982-aacb-949fe3334713",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product \\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e048dd-db39-4d9a-b372-95579c42d84c",
   "metadata": {},
   "source": [
    "**Import template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae6e2d27-d596-48d7-8606-e63254b35f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f904512e-0fe0-443a-9fe1-c8428b80482b",
   "metadata": {},
   "source": [
    "**Create prompt templates from review template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8dda48f1-5490-41f8-829a-a081a3ef6f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\nFormat the output as JSON with the following keys:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: {text}\\n'))]\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288def1a-e797-4dfb-8257-56814f1c00b4",
   "metadata": {},
   "source": [
    "**Create messages to pass to OpenAI API endpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a47d836-74a0-471a-8ece-749b65074771",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = prompt_template.format_messages(text=customer_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3ba95a-93df-4e9f-94d9-69be81ebba64",
   "metadata": {},
   "source": [
    "**Create OpenAI endpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b2a3849-b7bc-460c-834e-6941e56d6b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    temperature=0.0, \n",
    "    model=llm_name,\n",
    "    # openai_api_key=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71486a2b-ca8a-4b3c-a5fc-f56b19fff95c",
   "metadata": {},
   "source": [
    "**Call endpoint and get response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0277c23-0f67-493f-8b17-26f9140c7edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"gift\": true,\n",
      "    \"delivery_days\": 2,\n",
      "    \"price_value\": [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = chat(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c787737-1549-488e-bb95-5b9e3a2628eb",
   "metadata": {},
   "source": [
    "**Note that the response should have been a JSON, but is actually just a string which looks like a JSON**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "043afaa3-8be9-4536-9756-ea315e1ad7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cf91cc-0dd1-420a-8b3c-921e845cd6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will get an error by running this line of code \n",
    "# because'gift' is not a dictionary\n",
    "# 'gift' is a string\n",
    "response.content.get('gift')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e27fab8-a5ba-4b71-b1a4-4ba7355fb31d",
   "metadata": {},
   "source": [
    "### Parse the LLM output string into a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4a608e8-2b30-479c-a8ec-4f757ec9f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d18171-9ceb-43c3-9b98-f35eb2dfe82c",
   "metadata": {},
   "source": [
    "**Specify the schema for each variable using langchain ResponseSchema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "317695ba-d06a-40ff-ad9c-317f075abaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gift_schema = ResponseSchema(name=\"gift\",\n",
    "                             description=\"Was the item purchased\\\n",
    "                             as a gift for someone else? \\\n",
    "                             Answer True if yes,\\\n",
    "                             False if not or unknown.\")\n",
    "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
    "                                      description=\"How many days\\\n",
    "                                      did it take for the product\\\n",
    "                                      to arrive? If this \\\n",
    "                                      information is not found,\\\n",
    "                                      output -1.\")\n",
    "price_value_schema = ResponseSchema(name=\"price_value\",\n",
    "                                    description=\"Extract any\\\n",
    "                                    sentences about the value or \\\n",
    "                                    price, and output them as a \\\n",
    "                                    comma separated Python list.\")\n",
    "\n",
    "response_schemas = [gift_schema, \n",
    "                    delivery_days_schema,\n",
    "                    price_value_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86094d90-a571-4af0-9ede-983ff52e678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "299723b7-7b18-43c1-9183-b9bd2047cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "72949331-4ba4-4937-97d3-4fddf0facb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
      "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c56526ec-5307-4b1f-a311-18815d8646ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_template_2 = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product\\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
    "\n",
    "messages = prompt.format_messages(text=customer_review, \n",
    "                                format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a0d6909-3e9f-4c42-b2b7-9d9da5bc7e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the following text, extract the following information:\n",
      "\n",
      "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
      "\n",
      "delivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\n",
      "\n",
      "price_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n",
      "\n",
      "text: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n",
      "\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
      "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c28b750-5822-4f39-9356-6a2d633fe341",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "89075636-2868-4737-bbc2-75bed7549d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"gift\": true,\n",
      "\t\"delivery_days\": \"2\",\n",
      "\t\"price_value\": [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d71f29-50d3-476f-99ec-233afe281cc0",
   "metadata": {},
   "source": [
    "**Still a string that looks like a dict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a75df0-35a1-42e1-9873-02d1541627b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"gift\": true,\n",
    "    \"delivery_days\": 2,\n",
    "    \"price_value\": [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b5603b-46fd-46d9-8e84-d9406769ce79",
   "metadata": {},
   "source": [
    "**Therefore, use the parser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59bacd24-22c2-49fc-9038-224c0b2143c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = output_parser.parse(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "747187c8-7fde-428b-b568-5cc71e353aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': True,\n",
       " 'delivery_days': '2',\n",
       " 'price_value': [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45a97fe1-04da-4063-97d2-b8f9effae6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': True,\n",
       " 'delivery_days': '2',\n",
       " 'price_value': [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'gift': True,\n",
    " 'delivery_days': '2',\n",
    " 'price_value': [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0429d53-dad3-4b41-b663-8abe9b7cde23",
   "metadata": {},
   "source": [
    "**This is now actually of type(dict)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c56683e-a928-4c25-9a7e-258983db36be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1dc59762-3f4b-4208-bfb7-ebc5d823ac5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict.get('delivery_days')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b16f0c7-2654-49ed-8857-bb06af225e1e",
   "metadata": {},
   "source": [
    "### Source: https://learn.deeplearning.ai/langchain/lesson/2/models,-prompts-and-parsers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
