{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba46c09c-7a02-41c0-ae56-4421b0a2a7e7",
   "metadata": {},
   "source": [
    "# LangChain: Agents\n",
    "\n",
    "## Outline:\n",
    "\n",
    "* Using built in LangChain tools: DuckDuckGo search and Wikipedia\n",
    "* Defining your own tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa3bdf5-0e5d-4001-a732-affbccc07e7d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## EITHER: use your [OpenAI API Key](https://platform.openai.com/account/api-keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52af4a3a-972c-4b30-85a8-5fc7512625c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d856b05a-f54d-452f-aaee-9c8981be12b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f25984-5348-4bc6-af35-2b19d119b2a7",
   "metadata": {},
   "source": [
    "## OR: use [LocalAI as an OpenAI replacement](https://localai.io/howtos/easy-request-openai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d7ddea0-0899-4311-bac0-06907b32abfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# Specify the port your LocalAI docker container runs on\n",
    "# openai.api_base = \"http://localhost:8080/v1\"  # default\n",
    "openai.api_base = \"http://localhost:9095/v1\"  # for lunademo\n",
    "openai.api_key = \"sx-xxx\"  # not needed for LocalAI (dummy)\n",
    "OPENAI_API_KEY = \"sx-xxx\"\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ddcf635-76ce-40da-9ffd-7a2fff551d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model you are using\n",
    "# llm_model = \"\"\n",
    "llm_model = \"lunademo\"  # for lunademo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf865d5d-1056-413d-9b87-f74f987440c9",
   "metadata": {},
   "source": [
    "## Built-in LangChain tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d573c030-6540-42c5-ad64-a2d63aba6799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce0f07b4-3f9a-41e1-91a0-7330e5b791d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2f6f47-3e46-4c4d-b8fc-5f690277d635",
   "metadata": {},
   "source": [
    "**We initialize the LLM**\n",
    "- it's important here to set the *temperature* to 0 (degree of randmoness) as we're using the LLM as the reasoning engine for the agent to connect to other sources of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b97ccdec-68e2-4eff-84f1-7eec5aa4a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=llm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49e2d35-d73c-40bc-a979-4dbbc6d285bc",
   "metadata": {},
   "source": [
    "**We are loading 2 tools here: *math* and *wikipedia***\n",
    "- *math* is a Chain itself, which uses an LLM in conjunction with a calculator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aba8f83-754f-4be3-b45f-ed9d826e4d4b",
   "metadata": {},
   "source": [
    "## FixMe: tools with LocalAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db58d43c-5377-46c5-b192-a15af46a869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"llm-math\",\"wikipedia\"], llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af95ba30-459a-4cba-8c34-4f1751f3e9de",
   "metadata": {},
   "source": [
    "**We initialize the agent**\n",
    "- tools (loaded above)\n",
    "- LLM (declared before)\n",
    "- type of agent, here **CHAT_ZERO_SHOT_REACT_DESCRIPTION**\n",
    "    - an agent optimized to work with Chatmodels as we use ChatOpenAI in this example *(use different one for Llama?)*\n",
    "    - *React* is a prompting technique to get the best reasoning perfomance out of the LLM\n",
    "- we also set *handle_parsing_errors* to *True*\n",
    "    - if the LLM outputs misformatted responses which cannot be turned into actions, we pass them back into the LLM to correct itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdf403f1-f2ab-462d-a09f-ac35f7c7c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent= initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe05d82-2686-4953-9d17-b297c7819328",
   "metadata": {},
   "source": [
    "**Prompt the agent with a task**\n",
    "- it uses the *math* Chain to come up with a response\n",
    "- try different prompts, see the chain of thought (if *verbose* and *debug* are *True*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb2a941-c9de-448c-87a6-a8499b878bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent(\"What is the 25% of 300?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b430379d-7f50-4066-864c-55d1c7f4dc6a",
   "metadata": {},
   "source": [
    "**This is a more interesting example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59ff3c8-0f37-43ae-961c-ceccaa47d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent(\"When I was 6, my sister was 3 years younger than me. Now I am 65. How old is my sister?\")  # it worked the first time for me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70848e68-e3d2-49bb-bd93-4db40f1a69f7",
   "metadata": {},
   "source": [
    "## Wikipedia example\n",
    "- we ask a question, the agent realizes it should use Wikipedia to find a response\n",
    "- it will find two different Wikipedia entries for the name we specified and uses its chain of thought to go for the more plausible one\n",
    "- if *debug* is *True* we can see the chain of thought again (with different colors for different steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9edc1e-928e-44bb-a93c-5da67fee879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tom M. Mitchell is an American computer scientist \\\n",
    "and the Founders University Professor at Carnegie Mellon University (CMU)\\\n",
    "what book did he write?\"\n",
    "result = agent(question) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbddc79-9109-4512-9e67-9de89f307cac",
   "metadata": {},
   "source": [
    "## Python Agent\n",
    "- this is probably the most exciting one, similar to *ChatGPT* with *CodeInterpreter*\n",
    "- we use the same LLM as before and give it the **PythonREPLTool** tool\n",
    "    - an environment for executing code, similar to Jupyter Notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21777ace-78df-489d-84e6-f13c76164f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_python_agent(\n",
    "    llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "617ee9cb-c208-40a5-84b2-ef0bcaf0f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_list = [[\"Harrison\", \"Chase\"], \n",
    "                 [\"Lang\", \"Chain\"],\n",
    "                 [\"Dolly\", \"Too\"],\n",
    "                 [\"Elle\", \"Elem\"], \n",
    "                 [\"Geoff\",\"Fusion\"], \n",
    "                 [\"Trance\",\"Former\"],\n",
    "                 [\"Jen\",\"Ayai\"]\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77346aeb-1068-4569-a363-33dbcfc32e9f",
   "metadata": {},
   "source": [
    "**The results of our prompt are passed back into the agent, so it can decide what to do next**\n",
    "- this is a pretty straightforward task and works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d979de61-edea-4135-94b8-e7f52cdffd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(f\"\"\"Sort these customers by \\\n",
    "last name and then first name \\\n",
    "and print the output: {customer_list}\"\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c016b9e-ed97-4678-92d8-b1b78d7b6a70",
   "metadata": {},
   "source": [
    "- this instead is a bit harder, and the LLM failed to do it for me\n",
    "- it's important to **use the *print* statement** to feed the output back into the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bd1b8d-5921-48c8-a8c8-2aec7038474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_function(num1, num2):\n",
    "    num3 = (num2 + num1) \n",
    "    num3 = num3 / num2\n",
    "    return num3\n",
    "\n",
    "num1 = 1\n",
    "num2 = 5\n",
    "    \n",
    "agent.run(f\"\"\"\n",
    "Run this function with these \\\n",
    "two variables and print the output: \\\n",
    "{test_function}, {num1}, {num2}\"\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f8cdf5-0354-4f87-b772-b82dc6d42634",
   "metadata": {},
   "source": [
    "#### View detailed outputs of the chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61055f92-4cc3-4412-9b75-d34e4909f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug=True\n",
    "agent.run(f\"\"\"Sort these customers by \\\n",
    "last name and then first name \\\n",
    "and print the output: {customer_list}\"\"\") \n",
    "langchain.debug=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cf23fe-a943-4f53-ba9b-2118bdfda5ea",
   "metadata": {},
   "source": [
    "## Define your own tool\n",
    "- you can connect LangChain to your own custom tool/source of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4631adb8-2de4-4bb0-a9ef-bb738c1407fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install DateTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1579a387-80f6-4c1a-bc61-e7d858ec9375",
   "metadata": {},
   "source": [
    "**First we import the *tool* decorator**\n",
    "- can be applied to any function to turn it into a tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a658928-9a36-4ba5-8851-5700156014aa",
   "metadata": {},
   "source": [
    "from langchain.agents import tool\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9a49b3-8982-4a0b-87b0-60faff59e57c",
   "metadata": {},
   "source": [
    "**In addition to the function itself, we also add a very detailed docstring**\n",
    "- the docstring will help the agent to know when and how to call this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d945b13-7723-4ee3-9f22-263f9b74b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def time(text: str) -> str:\n",
    "    \"\"\"Returns todays date, use this for any \\\n",
    "    questions related to knowing todays date. \\\n",
    "    The input should always be an empty string, \\\n",
    "    and this function will always return todays \\\n",
    "    date - any date mathmatics should occur \\\n",
    "    outside this function.\"\"\"\n",
    "    return str(date.today())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa68417-6466-49c2-82a7-670d91f6c378",
   "metadata": {},
   "source": [
    "**We create another agent**\n",
    "- this time we add the time tool to the tools used before (for the previous agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723496b7-c9f0-4a7c-a14a-f335af1471c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent= initialize_agent(\n",
    "    tools + [time], \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f145738-439f-4762-bb41-a412c6834ede",
   "metadata": {},
   "source": [
    "**Note**: \n",
    "\n",
    "The agent will sometimes come to the wrong conclusion (agents are a work in progress!). \n",
    "\n",
    "If it does, please try running it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1828266-1e4c-41c6-a27c-1d0ec6eeb3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    result = agent(\"whats the date today?\") \n",
    "except: \n",
    "    print(\"exception on external access\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff544ad4-f44c-42f3-81e9-c151ee63815a",
   "metadata": {},
   "source": [
    "### Source: https://learn.deeplearning.ai/langchain/lesson/7/agents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
