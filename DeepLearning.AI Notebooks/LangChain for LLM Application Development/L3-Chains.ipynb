{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7edede31-2a6e-4d9e-bde5-5c1f7b2ceb5f",
   "metadata": {},
   "source": [
    "# Chains in LangChain\n",
    "\n",
    "## Outline\n",
    "\n",
    "* LLMChain\n",
    "* Sequential Chains *(combine multiple chains, output of one chain is input of next chain)*\n",
    "  * SimpleSequentialChain *(subchains with single input/output)*\n",
    "  * SequentialChain *(subchains with multiple input/output)*\n",
    "* Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7beb6bf7-0ac5-4123-bf4e-9e37acd937ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8207e9dc-0d79-44a5-b67c-06e8fd1bed2f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## EITHER: use your [OpenAI API Key](https://platform.openai.com/account/api-keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbaf4242-96ad-4406-abb3-d5bff78d47cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b669012-8774-447b-b0a1-470beca32df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99322ec5-2cdf-4133-a022-63e92d1d89e7",
   "metadata": {},
   "source": [
    "## OR: use [LocalAI as an OpenAI replacement](https://localai.io/howtos/easy-request-openai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69fbca56-998b-44be-8e30-25ae81d4e4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# Specify the port your LocalAI docker container runs on\n",
    "# openai.api_base = \"http://localhost:8080/v1\"  # default\n",
    "openai.api_base = \"http://localhost:9095/v1\"  # for lunademo\n",
    "openai.api_key = \"sx-xxx\"  # not needed for LocalAI (dummy)\n",
    "OPENAI_API_KEY = \"sx-xxx\"\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "421096dc-98f0-4400-b63d-97df7b4cf392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model you are using\n",
    "# llm_model = \"\"\n",
    "# WARNING: not all LangChain functions work with custom LocalAI models, but they can be renamed, e.g. to 'gpt-3.5-turbo'\n",
    "llm_model = \"lunademo\"  # for lunademo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bf8353-f03f-45b4-914b-1c1d53118564",
   "metadata": {},
   "source": [
    "## Read our `csv` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20aa773c-182f-4bc3-af4f-f97e1e26db97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9737e1f3-42c1-4cff-98de-45719d5e0a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "213bad78-1a02-41e0-9d50-348fbcf4c187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Product                                             Review\n",
       "0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n",
       "1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n",
       "2      Luxury Air Mattress  This mattress had a small hole in the top of i...\n",
       "3           Pillows Insert  This is the best throw pillow fillers on Amazo...\n",
       "4  Milk Frother Handheld\\n   I loved this product. But they only seem to l..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f52aef-3300-4222-9be6-0d8a2e60bcae",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bd14d50-0abf-4aef-b832-5bc5856ce547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8ea6c7-562c-409d-8e85-0a91cf5c47c9",
   "metadata": {},
   "source": [
    "**Initialize the model - we are using a high temperature (randomness) here for more varied descriptions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "765ef70a-2abc-420c-89b6-06b7339f4df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, model=llm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b497194e-dd41-4649-a9a6-a6c19f84bfc7",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain\n",
    "- combine multiple chains, where output of one chain is input of next chain\n",
    "- subchains with single input/output\n",
    "- e.g. get the *name of company* from an individual *product description*, then get an *advertising slogan* for this company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c485a19-45c2-46d3-a08f-b1afd9b42a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94eb834d-daad-4e45-83be-5ad9dc709e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "\n",
    "# prompt template 1 - name from product description\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d8e0817-29e3-4c31-95fa-d18e3045f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2 - slogan from name\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6745d3f0-8695-4b1f-9473-0694e6c3c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59da67da-79ca-4942-8c83-cc7cf0c21354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example product from our csv\n",
    "product = \"Queen Size Sheet Set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10a10561-d922-4fcc-890b-d4ffdbb302d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mBased on your description, the best name to describe the company that makes the king size set with 4 pillowcases would be \"Sheets & More\". The company offers a wide range of bedding products, including king size sets with 4 pillowcases, and provides excellent customer service by sending additional pillowcases when needed.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mSheets & More is a company that offers high-quality bedding products, including king size sets with 4 pillowcases, and provides excellent customer service by sending additional pillowcases when needed.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sheets & More is a company that offers high-quality bedding products, including king size sets with 4 pillowcases, and provides excellent customer service by sending additional pillowcases when needed.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6818278a-92d8-484f-b06d-91c79421870d",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23bff125-dd8d-4b91-836f-4134325d599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4f80ed-6faf-4d72-ab34-1589b8fd1876",
   "metadata": {},
   "source": [
    "**1st: Translate the review to English**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aad476b5-f7f0-4c80-8501-bf945eee8cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd044f84-a373-4cab-82ff-870b1db0de4c",
   "metadata": {},
   "source": [
    "Note the output variable `English_Review` which is input to the next chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967f10cb-6978-43e8-ac6d-2f8c2fef1837",
   "metadata": {},
   "source": [
    "**2nd: Summarize review in one sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "334ddc97-27d8-4614-841d-90c1fc6a0849",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1db384a-e53b-4e8a-9641-6b69638ed0df",
   "metadata": {},
   "source": [
    "Note the output variable `summary` which is input to the next chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e51180f-873a-4e5c-8a4c-6384a67875da",
   "metadata": {},
   "source": [
    "**3rd: Get the language of the original review**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0f57afe-9a28-4e5d-b1a0-f88b2640ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983c2cf0-93b6-40ce-b935-d57a7b1586d5",
   "metadata": {},
   "source": [
    "Note the original input variable `Review` is used again here and output variable `summary` is input to the next chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb42d54-c7f4-4772-b459-7d110b503818",
   "metadata": {},
   "source": [
    "**4th: Now take multiple inputs**\n",
    "- summary (calculated with 2nd chain)\n",
    "- language (calculated with 3rd chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e5b8e83-e8cf-4c23-bacf-fe2cf2ffb3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 4: follow up message in specified language\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07729031-b689-4d23-935b-b08ef9321ab5",
   "metadata": {},
   "source": [
    "**The overall chain (whick takes the four created chains)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6319a63e-860c-42ae-8626-a3bd3e16c83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input = Review \n",
    "# and output = English_Review, summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82614341-f698-4cd6-843d-75f297021e62",
   "metadata": {},
   "source": [
    "**Now we run the overall chain over some of the data loaded from `Data.csv`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7a412f9-07b2-42dc-8532-fd9e831d9191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': \"Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\\nVieux lot ou contrefaçon !?\",\n",
       " 'English_Review': \"The taste is poor. The mousse does not hold, it's strange. I buy the same thing in the store and the taste is much better...\",\n",
       " 'summary': 'The store-bought version of the mousse is of better taste than the homemade version.',\n",
       " 'followup_message': 'Réponse aux commentaires: Le version achetée en magasin de la mousse est de meilleur goût que la version à domicile faite.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df.Review[5]\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c320cc-cd15-431b-b9ef-993cdbe64d73",
   "metadata": {},
   "source": [
    "**What happened:**\n",
    "- we took a French review from data\n",
    "- we translated it to English (*1st*)\n",
    "- we summarised it in one sentence (*2nd*)\n",
    "- we got the language of the original review (*3rd*)\n",
    "- we wrote a follow up message to the summary of the review in the language detected (*4th*)\n",
    "  \n",
    "- **this actually worked with LocalAI and `lunademo`, a very small model (~2GB)! How cool is that?!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f98100-8163-439e-aa12-ffa4fd42a91d",
   "metadata": {},
   "source": [
    "## Router Chain\n",
    "- if you save several subchains, each specialized to some specific type of input (e.g., related subjects)\n",
    "- decides which chain to pass through"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad7948f-e364-472d-bdb1-50129e252955",
   "metadata": {},
   "source": [
    "**Here we have different prompt templates, where each is good for answering questions from different fields**\n",
    "- math\n",
    "- physics\n",
    "- history\n",
    "- computer science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "189de1d3-1af9-424b-bdc4-a6ad91cf4e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a31c117-631f-444d-a6ec-e8dbc88a313a",
   "metadata": {},
   "source": [
    "**We can provide more info about the different templates**\n",
    "- name of the template\n",
    "- description of the template --> this is passed to the router chain, so it can decided which template to pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37f1a71e-e855-47a5-8c7e-41e6b25e6fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"history\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfc835a-d385-46d2-bde8-c9703f4421f6",
   "metadata": {},
   "source": [
    "- **MultiPromptChain** needed for routing between multiple different prompt templates\n",
    "- **LLMRouterChain** uses LLM itself to route between different subchains, uses `description` and `name` provided before\n",
    "- **RouterOutputParser** parses the output into a dict, to determine which chain to use and what the input to it should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f12a6c22-a85c-4869-8982-f3e3b9514873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain  # needed for routing between multiple different prompt templates\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffe27f7-a00f-443d-8c67-a1542e60c886",
   "metadata": {},
   "source": [
    "**Import and define the language model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55905bfd-6f94-4a25-a5b0-b8267c752554",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=llm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f079f54-5b00-4a49-86aa-bb9796e59e1c",
   "metadata": {},
   "source": [
    "**Create the destination chains**\n",
    "- will be called by the router chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "abf9acc0-6ae6-4aad-aa5b-33b63dc229b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)  # each destination chain is itself an LLMchain\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c7d896-20fb-49a6-bc14-3f51cfd0866e",
   "metadata": {},
   "source": [
    "**We also need a default chain (fallback)**\n",
    "- called when the router chain can't decide which subchain to use\n",
    "- in our example: whether a question is more math/physics related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d2312686-6c2c-4a81-84b9-5f7473aca3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7887cdb5-e752-4eef-a715-494c14907699",
   "metadata": {},
   "source": [
    "**Define the template that is used by the LLM to route between different chains**\n",
    "- has instructions of the task to be done\n",
    "- and specific formatting the output should be in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "40f62256-d0b9-4256-b6f8-4ea3c10c158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57560bb-7137-4b81-8822-a3deda98d0ad",
   "metadata": {},
   "source": [
    "**Put it all together to build the router chain**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303cb03e-61c9-42bb-a77d-160ff38a3cbd",
   "metadata": {},
   "source": [
    "- full router template, formatted with the destinations defined before\n",
    "- flexible to different destinations (e.g., add other subject to prompt templates and prompt infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e48517d-5648-458f-b24c-613ccb8b5379",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdfd438-d15b-4be9-984a-34f94803301c",
   "metadata": {},
   "source": [
    "- create the prompt template\n",
    "- note the parser, which helps decide which subchains to route  between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c898ed10-dea3-4960-a17a-210da4119c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e37cf9-03c1-4daa-82d7-18736f0860dd",
   "metadata": {},
   "source": [
    "- create the router chain by passing `llm` and overall `router_prompt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76dc22ba-6881-46ac-8688-240b5cdce771",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705db1a4-e7fe-47ed-94a2-85b976bb5b92",
   "metadata": {},
   "source": [
    "- put together: **the overall chain**\n",
    "- router chain, destination chains, default chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3bfb8446-bfe8-4fac-a796-f4bdc437fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e0cca954-54ea-42a1-9dcd-ffcc38b1dc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "history: {'input': 'What is the significance of the Black Death?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Black Death was a deadly pandemic that swept across Europe in the 14th century, causing the deaths of an estimated 75-200 million people. It was one of the most significant events in European history and had a profound impact on the social, economic, and political life of the continent.\\nThe significance of the Black Death lies in its impact on the population, the economy, and the political system of medieval Europe. It led to a significant decrease in population, which affected the social and economic structures of society. The plague also had a significant impact on the religious and political institutions of the time, as people turned to God for answers and sought spiritual guidance during the crisis.\\nFurthermore, the Black Death led to significant changes in the way people lived and worked, as well as in their attitudes towards death and the afterlife. The plague forced people to re-evaluate their priorities and values, leading to a greater emphasis on family and community over individual ambition.\\nIn terms of historical significance, the Black Death has been studied extensively and is widely regarded as one of the most significant events in European history. It has been used as a reference point for studying the impact of pandemics on society and the economy, as well as the role of religion and spirituality in times of crisis.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eab84be-861c-4258-ab71-0c11d1eae5c8",
   "metadata": {},
   "source": [
    "### Source: https://learn.deeplearning.ai/langchain/lesson/4/chains"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
