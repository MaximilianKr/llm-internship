{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "947f1556-f2f6-46e8-8e5d-ec04cf1bd941",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "\n",
    "Retrieval is the centerpiece of our retrieval augmented generation (RAG) flow. \n",
    "\n",
    "Let's get our vectorDB from before.\n",
    "\n",
    "- **MMR** increases diversity in the retrieved documents, which can be crucial for relevant information which does not seem relevant from first glance at semantic similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9a444f-2be4-4f54-a88a-46a4028f7888",
   "metadata": {},
   "source": [
    "## Vectorstore retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b57a61-e671-4559-aca1-5b30b4db1083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fac950f-bf00-42fc-ae1c-bff90f14d6b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## EITHER: get your [OpenAI API Key](https://platform.openai.com/account/api-keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49639de8-e376-40fc-9e92-c9c862da0f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e36aaf-652c-42b1-9561-3ccf27c36b1a",
   "metadata": {},
   "source": [
    "## OR: use [LocalAI as an OpenAI replacement](https://localai.io/howtos/easy-request-openai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0db3eb0d-8366-40f4-bd93-131823505187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# Specify the port your LocalAI docker container runs on\n",
    "openai.api_base = \"http://localhost:8080/v1\"  # default\n",
    "openai.api_key = \"sx-xxx\"\n",
    "OPENAI_API_KEY = \"sx-xxx\"\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44029866-3345-4ca7-9531-517b21d5509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model you are using\n",
    "# llm_model = \"\"\n",
    "llm_model = \"lunademo\"\n",
    "# llm_model = \"thebloke__wizardlm-13b-v1-0-uncensored-superhot-8k-ggml__wizardlm-13b-v1.0-superhot-8k.ggmlv3.q4_k_m.bin\"\n",
    "# llm_model = \"llama2-7b-uncensored\"\n",
    "# llm_model = \"mistral-7b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a54b909-71d4-4cb3-b4e3-f90d6c1b0b9a",
   "metadata": {},
   "source": [
    "### Similarity Search\n",
    "- the problem can be that we retrieve relevant parts, but we omit parts which do not seem relevent\n",
    "- here: the mushroom is actually poisonous, but we don't get this information with the used query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc616e93-1825-43e4-ab47-9ec62f126278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "849238ed-ee35-42fb-9d73-e56887345dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "261f7fb1-13f0-4d8d-937d-ed710d49e64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287\n"
     ]
    }
   ],
   "source": [
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")\n",
    "\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2188b98-20c5-473d-855f-e3c5ee940f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
    "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
    "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "568245e0-4ebe-4774-b397-dbed48c12f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldb = Chroma.from_texts(texts, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bdd8dea-c5a8-460f-8515-ea4ff292f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tell me about all-white mushrooms with large fruiting bodies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7427654e-56a2-47a3-8a8a-f643e9d121b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).'),\n",
       " Document(page_content='A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldb.similarity_search(question, k=2)  # k=2, retrieve only 2 most relevant documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783c9695-cea7-4173-855e-25def87d3daa",
   "metadata": {},
   "source": [
    "**Now we use MMR (maximum marginal relevance) instead of simple similarity search**\n",
    "- we leave `k=2` for 2 returned documents, but set `fetch_k=3` to retrieve all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cb055ea-541d-47a4-a843-585daba03ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(page_content='The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldb.max_marginal_relevance_search(question,k=2, fetch_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b37848d-25f9-4e4b-88e4-a0664384720d",
   "metadata": {},
   "source": [
    "### Addressing Diversity: Maximum marginal relevance\n",
    "\n",
    "Last class we introduced one problem: how to enforce diversity in the search results.\n",
    " \n",
    "`Maximum marginal relevance` strives to achieve both relevance to the query *and diversity* among the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac0de5c2-4157-4e94-a4f1-49ab8a9b4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "docs_ss = vectordb.similarity_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35889aa4-4b8c-4a2c-8dda-b1f6d37ab456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'than any that you may choose to do yourself in your project. So all the homeworks can be \\ndone in MA'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_ss[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0372ae6-3d60-456c-a0d4-83cf96b037c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'of the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \\n[inaudible'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_ss[1].page_content[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463dc9f1-98b4-4e24-8f84-6b24f4ba5492",
   "metadata": {},
   "source": [
    "**Note the difference in results with `MMR`**\n",
    "- second document is different now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d0072d6-4256-493b-948f-49c2a8200557",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_mmr = vectordb.max_marginal_relevance_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f60d4402-c2eb-4ead-b477-5261c0192377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'than any that you may choose to do yourself in your project. So all the homeworks can be \\ndone in MA'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_mmr[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d3ef050-8674-48ca-8b12-ebee70cc1839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"alter medical practice as a result of me dical knowledge that's derived by applying \\nlearning algori\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_mmr[1].page_content[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fc53a2-506d-45a0-9f01-a0bb8eb0729d",
   "metadata": {},
   "source": [
    "### Addressing Specificity: working with metadata\n",
    "\n",
    "**In last lecture, we showed that a question about the third lecture can include results from other lectures as well**\n",
    "\n",
    "To address this, many vectorstores support operations on `metadata`.\n",
    "\n",
    "`metadata` provides context for each embedded chunk.\n",
    "\n",
    "- we use a `filter` here for metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a27fb2f-acfe-4435-be30-36b8570ec832",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9aeb4306-1a0c-4171-94bf-de09c30d4d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(\n",
    "    question,\n",
    "    k=3,\n",
    "    filter={\"source\":\"docs/cs229_lectures/MachineLearning-Lecture03.pdf\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9df0eb8-8c40-4281-899f-05d2a162bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88e84a8-acee-49be-8f7c-eaa6d8cd0cb5",
   "metadata": {},
   "source": [
    "### Addressing Specificity: working with metadata using self-query retriever\n",
    "**- instead of specifying this info manually, we use an LLM and pass it metadata to do it for us**\n",
    "\n",
    "But we have an interesting challenge: we often want to infer the metadata from the query itself.\n",
    "\n",
    "To address this, we can use `SelfQueryRetriever`, which uses an LLM to extract:\n",
    " \n",
    "1. The `query` string to use for vector search\n",
    "2. A metadata filter to pass in as well\n",
    "\n",
    "Most vector databases support metadata filters, so this doesn't require any new databases or indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd6e2eb1-792e-42da-b2a4-460a29679f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c745d57-c5cd-416a-a9de-0ef7181fee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The lecture the chunk is from, should be one of `docs/cs229_lectures/MachineLearning-Lecture01.pdf`, `docs/cs229_lectures/MachineLearning-Lecture02.pdf`, or `docs/cs229_lectures/MachineLearning-Lecture03.pdf`\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the lecture\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "434113f5-81a7-43c9-84cf-95d568e60995",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Lecture notes\"\n",
    "llm = OpenAI(\n",
    "    model = \"lunademo\",\n",
    "    temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7008ec7a-f64e-43ae-b492-df1e4bfe4c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02579428-f79e-4837-ab78-ff50de2db9a7",
   "metadata": {},
   "source": [
    "**You will receive a warning** about predict_and_parse being deprecated the first time you executing the next line. This can be safely ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da95f7b1-a971-41f1-9485-21f591dbf64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03181a57-1ca2-42de-8e2b-e5a079ce8798",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b386063a-a0e3-47ee-9a45-cd288161e67e",
   "metadata": {},
   "source": [
    "### Additional tricks: compression\n",
    "\n",
    "Another approach for improving the quality of retrieved docs is compression.\n",
    "\n",
    "Information most relevant to a query may be buried in a document with a lot of irrelevant text. \n",
    "\n",
    "Passing that full document through your application can lead to more expensive LLM calls and poorer responses.\n",
    "\n",
    "Contextual compression is meant to fix this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80de1ebb-ef3a-4482-914d-7b6c251e510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed1ded2-7252-4987-bd8c-a3343e0f98da",
   "metadata": {},
   "source": [
    "**We define a custom function here to pretty print the docs**\n",
    "- they're often very long and difficult to print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e0c1a60-99f3-42cb-b8e3-67c8dbb31f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afaade87-041d-4f93-9803-ed5b817ddf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap our vectorstore\n",
    "llm = OpenAI(\n",
    "    model = \"lunademo\",\n",
    "    temperature=0)\n",
    "compressor = LLMChainExtractor.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7a1274d-cb72-4d75-917d-4e6655ccb4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c9b7fc1-ca99-4dab-bd6d-a140949f4ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "\"knowledge of C or Java specifically.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "- \"what if your data doesn't lie in a two-dimensional or three-dimensional or even a finite dimensional space, but is it possible - what if your data actually lies in an infinite dimensional space?\" - this sentence explains that the context is about medical data and the possibility of it being infinite dimensional.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "- \"there won't be video you can safely sit there and make faces  at me, and that won't show, okay?\"\n",
      "- \"On the third page, there's a section that says Online Resources.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "- \"MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data.\" - This sentence describes the purpose and functionality of MATLAB as a programming language for numerical computations. It also mentions that MATLAB is easy to learn and has many features for numerical computations. Therefore, the context of MATLAB being a programming language for numerical computations is relevant to the question about what was said about MATLAB. The answer is \"MATLAB is a programming language that is easy to learn and has many features for numerical computations.\"\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c6a241-b902-4ce1-a522-b26ca55c41dc",
   "metadata": {},
   "source": [
    "## Combining various techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "374fa4ab-509a-4395-9da0-f8cbda96540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(search_type = \"mmr\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04cb0541-57dc-4810-aa93-e63e187a15d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "\"knowledge of C or Java specifically.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "- \"most of you probably use learning algorithms\" (relevant to the question about whether the asker uses learning algorithms in their work)\n",
      "- \"every time you send US mail, you are using a learning algorithm\" (relevant to the question about whether the asker is aware of using learning algorithms in their work)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      ">>> \"So, for example, this is something that my students and I work on. If I give you the keys to the city, you will have to make a sequence of decisions over time.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "going to look at the size of the tumor and depe nding on the size of the tumor, we'll try to  figure out whether or not the tu mor is malignant or benign.  \n",
      "So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \n",
      "or 1, and so your data set ma y look something like that, righ t? And that's 1 and that's 0, okay? \n",
      "And so this is an example of a classification problem where the variable \n",
      "you're trying to predict is a discreet value. It 's either zero or 1.  \n",
      "And in fact, more generally, there will be many learning problems where we'll have more \n",
      "than one input variable, more than one input feature and use more than one variable to try \n",
      "to predict, say, whether a tumor is malignant  or benign. So, for example, continuing with \n",
      "this, you may instead have a data  set that looks like this. I'm gonna part this data set in a \n",
      "slightly different way now. And\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c16cf7e-bc67-46be-8efe-56c0647a2afc",
   "metadata": {},
   "source": [
    "## Other types of retrieval\n",
    "\n",
    "It's worth noting that vectordb as not the only kind of tool to retrieve documents. \n",
    "\n",
    "The `LangChain` retriever abstraction includes other ways to retrieve documents, such as TF-IDF or SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed3ed1b4-8a44-48c5-9097-de37b24556db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import SVMRetriever\n",
    "from langchain.retrievers import TFIDFRetriever\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e1727a3-1138-4553-b125-2bef8de1a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF\n",
    "loader = PyPDFLoader(\"MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()\n",
    "all_page_text=[p.page_content for p in pages]\n",
    "joined_page_text=\" \".join(all_page_text)\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,chunk_overlap = 150)\n",
    "splits = text_splitter.split_text(joined_page_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf4dce57-2c9a-4c73-b568-d745de577d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "svm_retriever = SVMRetriever.from_texts(splits,embedding)\n",
    "tfidf_retriever = TFIDFRetriever.from_texts(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce8ad983-19ad-4f61-a0c1-dea33b425776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\przvl\\Dropbox\\Uni\\Computerlinguistik\\05  WiSe 23 - 24\\Praktikum\\ZHAW\\llm-internship\\DeepLearning.AI Notebooks\\dlai\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"to things in web crawling and so on. But it's just  cool to show videos, so let me just show \\na bunch of them. This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog. I guess Sam Shriver in this class also worked \\non the project and Peter Renfrew and Mike and a few others. But I guess this really is a \\ngood dog/bad dog since it's a robot dog.  \\nThe second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \\non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \\nobstacles.  \\nBelow that, this is kind of a fun example.  Ashutosh Saxena and Jeff Michaels used \\nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \\navoiding obstacles.  \\nAnd on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \\nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \\nover an obstacle. Sorry. I know the video's kind of small. I hope you can sort of see it. \\nOkay?  \\nSo I think all of these are robots that I thi nk are very difficult to hand-code a controller \\nfor by learning these sorts of l earning algorithms. You can in relatively short order get a \\nrobot to do often pretty amazing things.  \\nOkay. So that was most of what I wanted to say today. Just a couple more last things, but \\nlet me just check what questions you have righ t now. So if there are no questions, I'll just\")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "docs_svm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "332c1a1d-7143-470a-b8d6-0fca6e5e33ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Saxena and Min Sun here did, wh ich is given an image like this, right? This is actually a \\npicture taken of the Stanford campus. You can apply that sort of cl ustering algorithm and \\ngroup the picture into regions. Let me actually blow that up so that you can see it more \\nclearly. Okay. So in the middle, you see the lines sort of groupi ng the image together, \\ngrouping the image into [inaudible] regions.  \\nAnd what Ashutosh and Min did was they then  applied the learning algorithm to say can \\nwe take this clustering and us e it to build a 3D model of the world? And so using the \\nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \\nworld looks like so that they could come up with a 3D model that you can sort of fly \\nthrough, okay? Although many people used to th ink it's not possible to take a single \\nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \\nalgorithm is the first step. They were able to.  \\nI'll just show you one more example. I like this  because it's a picture of Stanford with our \\nbeautiful Stanford campus. So again, taking th e same sort of clustering algorithms, taking \\nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \\nregions. And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.  You can sort of walk  into the ceiling, look\")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "docs_tfidf=tfidf_retriever.get_relevant_documents(question)\n",
    "docs_tfidf[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
